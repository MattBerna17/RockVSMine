{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dependencies used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split        # to split the train and test data\n",
    "from sklearn.linear_model import LogisticRegression         # the logistic regression model\n",
    "from sklearn.metrics import accuracy_score                  # to check the accuracy score of the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection and data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset to pandas dataframe\n",
    "sonar_data = pd.read_csv(\"./sonar_data.csv\", header=None)   # this file has no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_data.head()                                           # to display the first 5 rows of the dataset\n",
    "# get the number of rows and columns\n",
    "(rows, columns) = sonar_data.shape\n",
    "sonar_data.describe()                                       # gives the standard deviation of the data and other measures of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_data[60].value_counts()                               # gives the number of elements for value in the last column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we have a big difference between the number of values we can have, the dataset has \"biases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the values by mine and rock and calculate the mean value for each column\n",
    "sonar_data.groupby(60).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data and the labels\n",
    "datas = sonar_data.drop(columns=60, axis=0)                 # getting the data values (from column 0 to 59)\n",
    "labels = sonar_data[60]                                     # getting the label values (from column 60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the data between training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this sklearn function to split data and labels between test and train\n",
    "datas_train, datas_test, labels_train, labels_test = train_test_split(datas, labels, test_size=0.1, stratify=labels, random_state=1)\n",
    "# PARAMETERS:\n",
    "#   1, 2: split the data and label columns\n",
    "#   3: only 10% of the dataset is used as test\n",
    "#   4: we want to give the train and test sets the same \"percentage\" of the labels values, so that there are no biases in the train or test datasets\n",
    "#   5: order the datas in a random way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data shape: {datas.shape}     Labels shape: {labels.shape}\\nData and label train shape: {datas_train.shape}     Data and label test shape: {datas_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training:\n",
    "    We use the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the logistic regression model with the training data\n",
    "model.fit(datas_train, labels_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accuracy of the model on the training data\n",
    "train_prediction = model.predict(datas_train)\n",
    "training_accuracy = accuracy_score(train_prediction, labels_train)\n",
    "print(f\"Training accuracy score: {train_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accuracy of the model on the test data\n",
    "test_prediction = model.predict(datas_test)\n",
    "test_accuracy = accuracy_score(test_prediction, labels_test)\n",
    "print(f\"Test accuracy score: {train_prediction}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a prediction system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = ()\n",
    "# use a numpy array\n",
    "numpy_input = np.asarray(input_data)\n",
    "\n",
    "# reshape the numpy array as we predict one instance\n",
    "input_data_reshape = numpy_input.reshape(1, -1)\n",
    "prediction = model.predict(input_data_reshape)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
